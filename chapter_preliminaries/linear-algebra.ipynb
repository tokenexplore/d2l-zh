{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0a800f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.5000)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 标量\n",
    "X = torch.tensor(3.5) # 创建一个标量张量\n",
    "Y = torch.tensor(4)\n",
    "X + Y # 结果也是一个标量张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac5a4f2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([15, 16, 10])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 一维张量表示向量\n",
    "x = torch.tensor([11,12,14,15,16,10]) # 0到11的整数序列，步长为1，结果是一个一维张量\n",
    "# x[3] # 第i个索引元素\n",
    "x[3:7] # 切片操作，索引从0开始，包括3但不包括7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953bb0b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 长度\n",
    "len(x) # 张量的长度\n",
    "# 向量或轴的维度被用来表示向量或轴的长度，即向量或轴的元素数量。 然而，张量的维度用来表示张量具有的轴数。 在这个意义上，张量的某个轴的维数就是这个轴的长度\n",
    "x.shape # 张量的形状"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3c17c1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  4,  8],\n",
       "        [ 1,  5,  9],\n",
       "        [ 2,  6, 10],\n",
       "        [ 3,  7, 11]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.arange(12).reshape(3,4)\n",
    "X.T # 矩阵转置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c54e8a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True],\n",
       "        [True, True, True],\n",
       "        [True, True, True]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 对称矩阵（symmetric matrix）等于其转置\n",
    "A = torch.tensor([[1,2,3],[2,0,4],[3,4,5]])\n",
    "A == A.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c74e7f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[12, 13, 14, 15],\n",
       "        [16, 17, 18, 19],\n",
       "        [20, 21, 22, 23]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 张量（本小节中的“张量”指代数对象）是描述具有任意数量轴的维数组的通用方法\n",
    "X = torch.arange(24).reshape(2, 3, 4)\n",
    "X[1] # 取出第1个矩阵，索引从0开始\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c1eb4c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.],\n",
       "         [12., 13., 14., 15.],\n",
       "         [16., 17., 18., 19.]]),\n",
       " tensor([[ 0.,  2.,  4.,  6.],\n",
       "         [ 8., 10., 12., 14.],\n",
       "         [16., 18., 20., 22.],\n",
       "         [24., 26., 28., 30.],\n",
       "         [32., 34., 36., 38.]]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 张量运算\n",
    "A = torch.arange(20, dtype=torch.float32).reshape(5, 4)\n",
    "B = A.clone()  # 通过分配新内存，将A的一个副本分配给B\n",
    "A, A + B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9830ce98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0.,   1.,   4.,   9.],\n",
       "        [ 16.,  25.,  36.,  49.],\n",
       "        [ 64.,  81., 100., 121.],\n",
       "        [144., 169., 196., 225.],\n",
       "        [256., 289., 324., 361.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A * B #两个矩阵的按元素乘法称为Hadamard积"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed29bf0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 2.,  3.,  4.,  5.],\n",
       "         [ 6.,  7.,  8.,  9.],\n",
       "         [10., 11., 12., 13.],\n",
       "         [14., 15., 16., 17.],\n",
       "         [18., 19., 20., 21.]]),\n",
       " tensor([[ 0.,  3.,  6.,  9.],\n",
       "         [12., 15., 18., 21.],\n",
       "         [24., 27., 30., 33.],\n",
       "         [36., 39., 42., 45.],\n",
       "         [48., 51., 54., 57.]]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将张量乘以或加上一个标量不会改变张量的形状，其中张量的每个元素都将与标量相加或相乘。\n",
    "A + 2,A * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9008e0cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 降维\n",
    "# 求和\n",
    "# A.sum() # 所有元素求和\n",
    "\n",
    "# 按行或按列求和\n",
    "A.sum(axis=0), A.sum(axis=1) # axis=0表示按列，axis=1表示按行，此时变为一维张量\n",
    "A.sum(axis=0).shape\n",
    "\n",
    "A.sum(axis=0, keepdim=True) # 保持二维张量的形状不变\n",
    "# A.sum(axis=1, keepdim=True).shape  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5cdb204e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.],\n",
       "         [12., 13., 14., 15.],\n",
       "         [16., 17., 18., 19.]]),\n",
       " tensor([ 8.,  9., 10., 11.]),\n",
       " tensor([[ 1.5000],\n",
       "         [ 5.5000],\n",
       "         [ 9.5000],\n",
       "         [13.5000],\n",
       "         [17.5000]]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \n",
    "# A.sum(axis=[0,1]) # 沿着行和列求和，等价于A.sum()，结果是一个标量\n",
    "\n",
    "# 平均值\n",
    "# A.mean(), A.sum()/A.numel() # A.numel()返回张量中元素的数量\n",
    "\n",
    "# 指定轴方向计算平均值\n",
    "A,A.mean(axis=0), A.mean(axis=1, keepdim=True) # keepdim=True保持二维张量的形状不变"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b13cacbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6.],\n",
       "        [22.],\n",
       "        [38.],\n",
       "        [54.],\n",
       "        [70.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 非降维求和,有时在调用函数来计算总和或均值时保持轴数不变会很有用\n",
    "A.sum(axis=1, keepdim=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e47272b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.],\n",
       "         [12., 13., 14., 15.],\n",
       "         [16., 17., 18., 19.]]),\n",
       " tensor([[ 6.],\n",
       "         [22.],\n",
       "         [38.],\n",
       "         [54.],\n",
       "         [70.]]),\n",
       " tensor([[0.0000, 0.1667, 0.3333, 0.5000],\n",
       "         [0.1818, 0.2273, 0.2727, 0.3182],\n",
       "         [0.2105, 0.2368, 0.2632, 0.2895],\n",
       "         [0.2222, 0.2407, 0.2593, 0.2778],\n",
       "         [0.2286, 0.2429, 0.2571, 0.2714]]),\n",
       " tensor([[ 8.,  9., 10., 11.]]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A,A.sum(axis=1, keepdim=True),A/A.sum(axis=1, keepdim=True),A.mean(axis=0, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c36ec6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.],\n",
       "         [12., 13., 14., 15.],\n",
       "         [16., 17., 18., 19.]]),\n",
       " tensor([[ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  6.,  8., 10.],\n",
       "         [12., 15., 18., 21.],\n",
       "         [24., 28., 32., 36.],\n",
       "         [40., 45., 50., 55.]]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 沿某个轴计算A元素的累积总和\n",
    "A,A.cumsum(axis=0) # 沿着轴0累加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8c344fb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(4.), tensor(4.), tensor(4.))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 向量点积，结果是一个标量\n",
    "y = torch.ones(4, dtype=torch.float32)\n",
    "y,y.shape,y.T,y.T.shape,y.dot(y)\n",
    "\n",
    "# 等价于\n",
    "y.dot(y), (y * y).sum(), y.T @ y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e138353d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 4]), torch.Size([4]), tensor([ 14.,  38.,  62.,  86., 110.]))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 矩阵-向量积\n",
    "x = torch.arange(4, dtype=torch.float32)\n",
    "A.shape,x.shape,torch.mv(A, x) # mv表示matrix-vecotrtor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8c2f278c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 4]),\n",
       " torch.Size([4, 3]),\n",
       " tensor([[ 6.,  6.,  6.],\n",
       "         [22., 22., 22.],\n",
       "         [38., 38., 38.],\n",
       "         [54., 54., 54.],\n",
       "         [70., 70., 70.]]))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 矩阵乘法\n",
    "B = torch.ones(4, 3)\n",
    "A.shape, B.shape, torch.mm(A, B) # mm表示matrix-matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e404337f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 向量范数\n",
    "u = torch.tensor([3.0, -4.0])\n",
    "u.norm() # L2范数\n",
    "torch.abs(u).sum() # L1范数，等价于 u.norm(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cd6974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(49.6991)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 矩阵范数，L2范数矩阵元素平方和的平方根，目标，或许是深度学习算法最重要的组成部分（除了数据），通常被表达为范数\n",
    "A.norm() # L2范数"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
